import { NextResponse } from "next/server";
import { GoogleGenerativeAI } from "@google/generative-ai";
import { ChatbotMessageSchema } from "@/lib/schemas";
import { getSession } from "@/lib/auth";
import { supabaseAdmin } from "@/lib/supabase/server";

// Inicializa el cliente de Gemini
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");

const SYSTEM_PROMPT = `Eres el asistente de compras de COCONSA.
META: Recopilar datos para Orden de Compra:
- Almac√©n (de lista)
- Art√≠culos (nombre, cantidad, unidad, precio, proveedor)
- Justificaci√≥n
- Moneda (MXN/USD)
- Evidencia (opcional, el usuario puede adjuntar archivos con el bot√≥n de clip)

REGLAS:
1. ONE-SHOT: Si el usuario da toda la info de golpe, confirma y pregunta si crear la orden. No hagas preguntas extras.
2. FALTANTES: Si falta algo, pregunta SOLO lo faltante.
3. MULTI-ITEM: Detecta m√∫ltiples art√≠culos en un mensaje.
4. ARCHIVOS: Si el usuario menciona que adjuntar√° evidencia, confirma que puede usar el bot√≥n de clip (üìé).
5. ESTILO: Conciso, eficiente, amable. M√°x 2-3 l√≠neas.

EJEMPLO:
Usuario: "100 martillos, almac√©n Norte, AcerosMX, $50, obra nueva, MXN"
Asistente: "Listo: 100 martillos, Norte, AcerosMX, $50 MXN. Justificaci√≥n: obra nueva. ¬øAdjuntas evidencia o creo la orden?"`;

export async function POST(request: Request) {
  try {
    // Obtener sesi√≥n del usuario
    const session = await getSession();
    if (!session) {
      return NextResponse.json(
        { error: "No autorizado. Debes iniciar sesi√≥n." },
        { status: 401 }
      );
    }

    // Obtener datos del usuario desde la base de datos
    const { data: userData, error: userError } = await supabaseAdmin
      .from('users')
      .select('id, full_name')
      .eq('id', session.userId)
      .single();

    if (userError || !userData) {
      console.error('Error obteniendo usuario:', userError);
      return NextResponse.json(
        { 
          error: "No se pudieron obtener los datos de tu usuario",
          details: userError?.message || 'Usuario no encontrado'
        },
        { status: 500 }
      );
    }

    // Obtener lista de almacenes disponibles
    const { data: stores } = await supabaseAdmin
      .from('stores')
      .select('id, name')
      .order('name');

    // Obtener lista de proveedores disponibles
    const { data: suppliers } = await supabaseAdmin
      .from('suppliers')
      .select('id, commercial_name')
      .order('commercial_name');

    const body = await request.json();
    
    // Validar el request
    const validatedFields = ChatbotMessageSchema.safeParse(body);
    
    if (!validatedFields.success) {
      return NextResponse.json(
        { 
          error: "Datos inv√°lidos",
          details: validatedFields.error.flatten().fieldErrors,
        },
        { status: 400 }
      );
    }

    const { message, conversationHistory = [] } = validatedFields.data;

    // Verificar que la API key est√© configurada
    if (!process.env.GEMINI_API_KEY) {
      console.error("GEMINI_API_KEY no est√° configurada");
      return NextResponse.json(
        { error: "Configuraci√≥n del servidor incompleta" },
        { status: 500 }
      );
    }

    // Obtener el modelo
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

    // Construir el historial de conversaci√≥n
    const history = [
      {
        role: "user",
        parts: [{ text: SYSTEM_PROMPT }],
      },
      {
        role: "model",
        parts: [{ text: "Entendido. Actuar√© como asistente virtual amigable de COCONSA y ayudar√© a los usuarios a proporcionar su informaci√≥n de manera natural y conversacional." }],
      },
      ...conversationHistory.map((msg) => ({
        role: msg.role === "user" ? "user" : "model",
        parts: [{ text: msg.content }],
      })),
    ];

    // Iniciar chat con historial
    const chat = model.startChat({
      history,
      generationConfig: {
        maxOutputTokens: 200,
        temperature: 0.7,
      },
    });

    // Enviar el mensaje del usuario
    let botMessage: string;
    try {
      const result = await chat.sendMessage(message);
      const response = result.response;
      botMessage = response.text();
      console.log('‚úÖ Gemini response:', botMessage);
    } catch (geminiError: any) {
      console.error('‚ùå Error de Gemini:', geminiError);
      throw new Error(`Error de Gemini API: ${geminiError?.message || 'Error desconocido'}`);
    }

    // Extraer informaci√≥n estructurada usando IA (segunda pasada) para mayor precisi√≥n
    const fullHistory = [...conversationHistory, { role: "user", content: message }, { role: "assistant", content: botMessage }];
    const extractedData = await extractOrderDataWithAI(
      fullHistory,
      userData,
      stores || [],
      suppliers || []
    );
    console.log('‚úÖ Datos extra√≠dos:', extractedData);

    return NextResponse.json({
      success: true,
      message: botMessage,
      extractedData,
      availableStores: stores || [],
      availableSuppliers: suppliers || [],
      conversationHistory: [
        ...conversationHistory,
        { role: "user", content: message },
        { role: "assistant", content: botMessage },
      ],
    });

  } catch (error: any) {
    console.error("Error en el chatbot:", error);
    return NextResponse.json(
      { 
        error: "Error al procesar la solicitud",
        details: error?.message || 'Error desconocido',
        stack: process.env.NODE_ENV === 'development' ? error?.stack : undefined
      },
      { status: 500 }
    );
  }
}

/**
 * Extrae informaci√≥n estructurada usando una llamada dedicada a la IA.
 * Esto es mucho m√°s robusto que Regex para estructuras complejas como arrays de items.
 */
async function extractOrderDataWithAI(
  conversationHistory: Array<{ role: string; content: string }>,
  userData: any,
  stores: any[],
  suppliers: any[]
) {
  try {
    const extractionModel = genAI.getGenerativeModel({ 
      model: "gemini-2.5-flash",
      generationConfig: {
        responseMimeType: "application/json",
        temperature: 0.1, // Baja temperatura para mayor determinismo en JSON
      }
    });

    // Convertir conversaci√≥n a texto plano para el prompt
    const conversationText = conversationHistory
      .map((msg) => `${msg.role === 'user' ? 'USUARIO' : 'ASISTENTE'}: ${msg.content}`)
      .join("\n");

    const extractionPrompt = `
      Analiza la siguiente conversaci√≥n entre un asistente de compras y un usuario.
      Tu objetivo es extraer los datos de la Orden de Compra en formato JSON ESTRICTO.

      INFORMACI√ìN DE CONTEXTO:
      - Solicitante: ${userData.full_name} (ID: ${userData.id})
      - Almacenes disponibles: ${JSON.stringify(stores.map(s => ({ id: s.id, name: s.name })))}
      - Proveedores disponibles: ${JSON.stringify(suppliers.map(s => ({ id: s.id, commercial_name: s.commercial_name })))}

      INSTRUCCIONES:
      1. Extrae el nombre del almac√©n/obra. Intenta coincidir con la lista de disponibles. Si encuentras coincidencia, incluye el ID.
      2. Extrae la lista de art√≠culos (items). Para cada uno: nombre, cantidad (n√∫mero), unidad, precio unitario (n√∫mero) y proveedor.
      3. Para el proveedor, intenta coincidir con la lista. Si encuentras coincidencia exacta o muy cercana, incluye el ID.
      4. Extrae la justificaci√≥n, moneda (MXN/USD) y retenci√≥n (si existe).
      5. Determina 'isComplete' como true SOLO SI tienes: almac√©n, justificaci√≥n, moneda y AL MENOS un art√≠culo completo (con todos sus campos: nombre, cantidad, unidad, precio, proveedor).

      FORMATO JSON ESPERADO:
      {
        "store_name": "Nombre extra√≠do o null",
        "store_id": "UUID coincidente o null",
        "items": [
          {
            "nombre": "Nombre del art√≠culo",
            "cantidad": 10,
            "unidad": "pza",
            "precioUnitario": 100.50,
            "proveedor": "Nombre proveedor",
            "proveedor_id": "UUID coincidente o null"
          }
        ],
        "justification": "Texto o null",
        "currency": "MXN",
        "retention": "Texto o null",
        "applicant_name": "${userData.full_name}",
        "applicant_id": "${userData.id}",
        "isComplete": boolean
      }

      CONVERSACI√ìN:
      ${conversationText}
    `;

    const result = await extractionModel.generateContent(extractionPrompt);
    const responseText = result.response.text();
    
    // Limpiar bloques de c√≥digo markdown si existen (aunque responseMimeType ayuda, a veces a√±ade ```json)
    const cleanedJson = responseText.replace(/```json\n?|\n?```/g, "").trim();
    
    return JSON.parse(cleanedJson);

  } catch (error) {
    console.error("Error en extracci√≥n IA:", error);
    // Fallback b√°sico para no romper el flujo si falla la IA de extracci√≥n
    return {
      store_name: null,
      items: [],
      isComplete: false,
      applicant_name: userData.full_name,
      applicant_id: userData.id
    };
  }
}


